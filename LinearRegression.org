#+TITLE: Linear regression from Scratch 
#+AUTHOR: Cristian Del Gobbo (pledged)
#+STARTUP: overview hideblocks indent
#+property: header-args:python :python python3 :session *Python* :results output :exports both :noweb yes :tangle yes:

* Introduction
In this notebook, I will implement a Linear Regression algorithm 
from scratch using Python, without relying on any external libraries.
* Code
The goal is to minimize the error function,
the error function is defined as:

E = (1/n) * Σ (y_i - (mx + b))^2

We want to find the values that minimize =E=. To do that, we can 
tweak the parameters =m= and =b= to minimize =E=. Therefore, we need 
to find the partial derivatives with respect to =m= and =b=.

This will allow us to change the two parameters using these updating formulas:

m = m - L * (∂E/∂m) 
        
b = b - L * (∂E/∂b)     

Where: 

∂E/∂m = (-2/n) * Σ x_i * (y_i - (mx + b))    

∂E/∂b = (-2/n) * Σ (y_i - (mx + b))

and =L= represents the learning rate, which determines the size of the 
steps the model takes to minimize the target function (=E=) and reach its 
optimal value.

Now Let's see the code!
** Python Code
#+name: lg
#+begin_src  python :python python3
  import matplotlib.pyplot as plt
  import pandas as pd
  import random

  num_rows = 100 
  # Creating random data 
  grades = [random.randint(1,100) for _ in range(num_rows)]
  time = [random.randint(1,100) for _ in range(num_rows)]

  data = {"grades":grades, "studytime": time}
  df = pd.DataFrame(data)

  # Define the Loss function (Not used, only for learning purposes)
  def loss_function(m, b, points):
      total_error = 0
      for i in range(len(points)):
          x = points.iloc[i].studytime
          y = points.iloc[i].grades
          total_error += (y - (m*x +b))**2 
      return total_error / float(len(points))

  # Define the Gradient Descent
  def gradient_descent(m_now, b_now, points, L):
      m_grad = 0
      b_grad = 0
      
      n = len(points)
      # Using the partial derivatives that we already found
      for i in range(n):
          x = points.iloc[i].studytime
          y = points.iloc[i].grades
          m_grad += -(2/n)*(x)*(y - (m_now*x+b_now))
          b_grad += -(2/n)*(y - (m_now*x+b_now))
          
      m = m_now - m_grad*L
      b = b_now - b_grad*L
      return m, b
  
  # Apply the Linear Regresion
  m = 0
  b = 0
  L = 0.0001
  epochs = 1000
  
  for i in range(epochs):
      if i % 100 == 0:
         print(f"Epoch: {i}")
      m, b = gradient_descent(m, b, df, L)
  
  print(m,b)
  #+end_src

#+RESULTS: lg
#+begin_example
Python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
Epoch: 0
Epoch: 1000
Epoch: 2000
Epoch: 3000
Epoch: 4000
Epoch: 5000
Epoch: 6000
Epoch: 7000
Epoch: 8000
Epoch: 9000
0.4350440650097158 22.32537170513932
#+end_example

Visualize the result with the parameters =m= and =b= learned by the model.
#+name: Viz
#+begin_src python :file lgs.png :python python3 :session *Python* :results output graphics file 
<<lg>> 
fig, ax = plt.subplots(1,1,figsize=(10,8))
ax.scatter(df["grades"], df["studytime"], color = "black")
ax.plot(df["studytime"], [m * x + b for x in df["studytime"]], color="red")
ax.set_xlabel("Grades")
ax.set_ylabel("Time Spent")
ax.set_title("Correlation between Grades and Time Spent")
ax.grid()
ax.spines["top"].set_visible(False)
ax.spines["right"].set_visible(False)
  
plt.tight_layout()
plt.savefig("lgs.png")
plt.show()
#+end_src

#+RESULTS: Viz
[[file:lgs.png]]

** C code
Implement the same alghoritm but in =C=.
#+begin_src C :results output :tangle lr.c
  #include <stdio.h>
  #include <stdlib.h>
  #include <time.h>

  float loss_function(float m, float b, float* studytime, float* grades, int size){
    float total_error = 0.f;
    float x, y;

    for(int i = 0; i<size; i++){
      x = studytime[i];
      y = grades[i];
      float error = y - (m*x + b);
      total_error += error * error;
    }
    return total_error/size;
  }

  void gradient_descent(float* m, float* b, float* studytime, float* grades, int size, float lr){
    float m_grad = 0.f;
    float b_grad = 0.f;
    float x, y;

    for(int i = 0; i<size; i++){
      x = studytime[i];
      y = grades[i];
      m_grad += (-2.0f/size)*(x)*(y - ((*m)*x + (*b)));
      b_grad += (-2.0f/size)*(y - ((*m)*x + (*b))); 
    }

    ,*m -= m_grad * lr;
    ,*b -= b_grad * lr;
  }

  int main(){
    int num_rows = 100;
    float studytime[num_rows];
    float grades[num_rows];
    float lr = 0.001f;
    float m = 0.f;
    float b = 0.f;
    int num_epochs = 10000;

    // Create random data
    srand(time(NULL));
    for(int i = 0; i<num_rows; i++){
      studytime[i] = (rand() % 101) / 100.f; // Normalize to range [0,1]
      grades[i] = (rand() % 101) / 100.f ;
    }

    // Training loop
    for(int epoch = 0; epoch<num_epochs; epoch++){
      gradient_descent(&m, &b, studytime, grades, num_rows, lr);
      if((epoch % 500) == 0)
        printf("Epoch: %d Loss: %.6g\n", epoch, loss_function(m, b, studytime, grades, num_rows));
    }
    puts("");

    // Print learned parameters
    printf("Learned parameters:\nm = %g\nb = %g\n", m, b);
    return 0;
  }

#+end_src

#+RESULTS:
#+begin_example
Epoch: 0 Loss: 0.334868
Epoch: 500 Loss: 0.12025
Epoch: 1000 Loss: 0.10322
Epoch: 1500 Loss: 0.101424
Epoch: 2000 Loss: 0.100858
Epoch: 2500 Loss: 0.100438
Epoch: 3000 Loss: 0.100075
Epoch: 3500 Loss: 0.099758
Epoch: 4000 Loss: 0.0994796
Epoch: 4500 Loss: 0.0992352
Epoch: 5000 Loss: 0.0990208
Epoch: 5500 Loss: 0.0988328
Epoch: 6000 Loss: 0.0986678
Epoch: 6500 Loss: 0.098523
Epoch: 7000 Loss: 0.098396
Epoch: 7500 Loss: 0.0982846
Epoch: 8000 Loss: 0.0981868
Epoch: 8500 Loss: 0.098101
Epoch: 9000 Loss: 0.0980257
Epoch: 9500 Loss: 0.0979597

Learned parameters:
m = 0.016786
b = 0.477077
#+end_example

Not surprisingly, =C= is much faster :).

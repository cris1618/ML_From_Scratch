#+TITLE: Linear regression from Scratch 
#+AUTHOR: Cristian Del Gobbo (pledged)
#+STARTUP: overview hideblocks indent
#+property: header-args:python :python python3 :session *Python* :results output :exports both :noweb yes :tangle yes:

* Introduction
In this Notebook I'll implement a Linear Regression
Alghoritm from scratch using Pyhton (No libraries).
* Code
Minimize the error function
Error function E = 1/n * sum(yi-(mx+b))^2 (Mean Squared Error).
We want to find the values that minimize E. To do that we can
tweak the parameters =m= and =b= to minimize E. Therefore, we need
to find the partial derivatives with respect to =m= and =b=.
#+name: lg
#+begin_src  python :python python3
  import matplotlib.pyplot as plt
  import pandas as pd
  import random

  num_rows = 100 
  grades = [random.randint(1,100) for _ in range(num_rows)]
  time = [random.randint(1,100) for _ in range(num_rows)]

  data = {"Grades":grades, "Studytime": time}
  df = pd.DataFrame(data)

  # Define the Loss function
  def loss_function(m, b, points):
      total_error = 0
      for i in range(len(points)):
          x = points.iloc[i].studytime
          y = points.iloc[i].grades
          total_error += (y - (m*x +b))**2 
      total_error / float(len(points))

  def 
  #+end_src

#+RESULTS: lg


#+name: Viz
#+begin_src  python :file lg.png :python python3 :session *Python* :results output graphics file
<<lg>> 
 fig, ax = plt.subplots(1,1,figsize=(10,8))
  ax.scatter(df["Grades"], df["Time Spent"])
  ax.set_xlabel("Grades")
  ax.set_ylabel("Time Spent")
  ax.set_title("Correlation between Grades and Time Spent")
  ax.grid()
  ax.spines["top"].set_visible(False)
  ax.spines["right"].set_visible(False)
  
  plt.tight_layout()
  plt.savefig("lg.png")
  plt.show()
#+end_src

#+RESULTS: Viz
[[file:lg.png]]
